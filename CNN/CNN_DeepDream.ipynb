{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_DeepDream.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maticvl/dataHacker/blob/master/CNN/CNN_DeepDream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0wsnPZtHXA9",
        "colab_type": "code",
        "colab": {},
        "outputId": "841102ed-e308-407b-a58e-53a941db5deb"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications import inception_v3\n",
        "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from keras import backend as K\n",
        "from scipy.ndimage import zoom\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from imageio import imwrite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBdM9Po7HXBC",
        "colab_type": "code",
        "colab": {},
        "outputId": "b3936a3a-79b5-4591-cad8-b5b25d673354"
      },
      "source": [
        "K.image_data_format()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'channels_last'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3RCFtJIHXBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = inception_v3.InceptionV3(weights = 'imagenet', include_top = False )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAO4G3kyHXBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_contributions = { 'mixed3':3,'mixed4':2, 'mixed5':1.5, 'mixed9':2, 'conv2d_94':2}\n",
        "\n",
        "#layer_contributions = { 'mixed3':3 , 'mixed9':2 }\n",
        "\n",
        "#layer_contributions = {'conv2d_16':1, 'mixed3':3, 'mixed5':1.5}\n",
        "\n",
        "#layer_contributions = { 'mixed3':3,'mixed4':2, 'conv2d_94':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6uCbfgPHXBJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "1e84f181-ac33-45f4-d725-a0690e973c66"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzXfv1M9HXBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nViaNMYHXBO",
        "colab_type": "code",
        "colab": {},
        "outputId": "fd6145eb-caa2-4f05-9122-1a84ca070c20"
      },
      "source": [
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_1': <keras.engine.input_layer.InputLayer at 0x22e85b90128>,\n",
              " 'conv2d_1': <keras.layers.convolutional.Conv2D at 0x22e85c2df98>,\n",
              " 'batch_normalization_1': <keras.layers.normalization.BatchNormalization at 0x22e85c2def0>,\n",
              " 'activation_1': <keras.layers.core.Activation at 0x22e85c2ddd8>,\n",
              " 'conv2d_2': <keras.layers.convolutional.Conv2D at 0x22efb2d81d0>,\n",
              " 'batch_normalization_2': <keras.layers.normalization.BatchNormalization at 0x22e85c9be80>,\n",
              " 'activation_2': <keras.layers.core.Activation at 0x22e85c9b630>,\n",
              " 'conv2d_3': <keras.layers.convolutional.Conv2D at 0x22e85d4ab00>,\n",
              " 'batch_normalization_3': <keras.layers.normalization.BatchNormalization at 0x22e85e28a20>,\n",
              " 'activation_3': <keras.layers.core.Activation at 0x22e85da8dd8>,\n",
              " 'max_pooling2d_1': <keras.layers.pooling.MaxPooling2D at 0x22e85e4fd30>,\n",
              " 'conv2d_4': <keras.layers.convolutional.Conv2D at 0x22e85e7b710>,\n",
              " 'batch_normalization_4': <keras.layers.normalization.BatchNormalization at 0x22e85e9ce10>,\n",
              " 'activation_4': <keras.layers.core.Activation at 0x22e85e9c828>,\n",
              " 'conv2d_5': <keras.layers.convolutional.Conv2D at 0x22e85f78f60>,\n",
              " 'batch_normalization_5': <keras.layers.normalization.BatchNormalization at 0x22e85f9fc18>,\n",
              " 'activation_5': <keras.layers.core.Activation at 0x22e85fc16a0>,\n",
              " 'max_pooling2d_2': <keras.layers.pooling.MaxPooling2D at 0x22e860a5fd0>,\n",
              " 'conv2d_9': <keras.layers.convolutional.Conv2D at 0x22e8638eeb8>,\n",
              " 'batch_normalization_9': <keras.layers.normalization.BatchNormalization at 0x22e85b90048>,\n",
              " 'activation_9': <keras.layers.core.Activation at 0x22e863c3240>,\n",
              " 'conv2d_7': <keras.layers.convolutional.Conv2D at 0x22e8619c9b0>,\n",
              " 'conv2d_10': <keras.layers.convolutional.Conv2D at 0x22e863e8d30>,\n",
              " 'batch_normalization_7': <keras.layers.normalization.BatchNormalization at 0x22e861e3160>,\n",
              " 'batch_normalization_10': <keras.layers.normalization.BatchNormalization at 0x22e86508ac8>,\n",
              " 'activation_7': <keras.layers.core.Activation at 0x22e862784e0>,\n",
              " 'activation_10': <keras.layers.core.Activation at 0x22e864ea320>,\n",
              " 'average_pooling2d_1': <keras.layers.pooling.AveragePooling2D at 0x22e866bee10>,\n",
              " 'conv2d_6': <keras.layers.convolutional.Conv2D at 0x22e8606f320>,\n",
              " 'conv2d_8': <keras.layers.convolutional.Conv2D at 0x22e861c3828>,\n",
              " 'conv2d_11': <keras.layers.convolutional.Conv2D at 0x22e86592cf8>,\n",
              " 'conv2d_12': <keras.layers.convolutional.Conv2D at 0x22e866be668>,\n",
              " 'batch_normalization_6': <keras.layers.normalization.BatchNormalization at 0x22e860ca4e0>,\n",
              " 'batch_normalization_8': <keras.layers.normalization.BatchNormalization at 0x22e862c2dd8>,\n",
              " 'batch_normalization_11': <keras.layers.normalization.BatchNormalization at 0x22e865eacc0>,\n",
              " 'batch_normalization_12': <keras.layers.normalization.BatchNormalization at 0x22e86703c18>,\n",
              " 'activation_6': <keras.layers.core.Activation at 0x22e86172ac8>,\n",
              " 'activation_8': <keras.layers.core.Activation at 0x22e8638ed68>,\n",
              " 'activation_11': <keras.layers.core.Activation at 0x22e865e4828>,\n",
              " 'activation_12': <keras.layers.core.Activation at 0x22e86703208>,\n",
              " 'mixed0': <keras.layers.merge.Concatenate at 0x22e867e4550>,\n",
              " 'conv2d_16': <keras.layers.convolutional.Conv2D at 0x22e86ad5cc0>,\n",
              " 'batch_normalization_16': <keras.layers.normalization.BatchNormalization at 0x22e86b06320>,\n",
              " 'activation_16': <keras.layers.core.Activation at 0x22e86ad5518>,\n",
              " 'conv2d_14': <keras.layers.convolutional.Conv2D at 0x22e868de9e8>,\n",
              " 'conv2d_17': <keras.layers.convolutional.Conv2D at 0x22e86c09c18>,\n",
              " 'batch_normalization_14': <keras.layers.normalization.BatchNormalization at 0x22e86924eb8>,\n",
              " 'batch_normalization_17': <keras.layers.normalization.BatchNormalization at 0x22e86c4eb38>,\n",
              " 'activation_14': <keras.layers.core.Activation at 0x22e8698bf98>,\n",
              " 'activation_17': <keras.layers.core.Activation at 0x22e86c33a90>,\n",
              " 'average_pooling2d_2': <keras.layers.pooling.AveragePooling2D at 0x22e86d27f28>,\n",
              " 'conv2d_13': <keras.layers.convolutional.Conv2D at 0x22e867aeda0>,\n",
              " 'conv2d_15': <keras.layers.convolutional.Conv2D at 0x22e86902b38>,\n",
              " 'conv2d_18': <keras.layers.convolutional.Conv2D at 0x22e86cd7be0>,\n",
              " 'conv2d_19': <keras.layers.convolutional.Conv2D at 0x22e86e01898>,\n",
              " 'batch_normalization_13': <keras.layers.normalization.BatchNormalization at 0x22e868b4d68>,\n",
              " 'batch_normalization_15': <keras.layers.normalization.BatchNormalization at 0x22e86a06dd8>,\n",
              " 'batch_normalization_18': <keras.layers.normalization.BatchNormalization at 0x22e86d49748>,\n",
              " 'batch_normalization_19': <keras.layers.normalization.BatchNormalization at 0x22e86edd6d8>,\n",
              " 'activation_13': <keras.layers.core.Activation at 0x22e8680bfd0>,\n",
              " 'activation_15': <keras.layers.core.Activation at 0x22e86a2aa20>,\n",
              " 'activation_18': <keras.layers.core.Activation at 0x22e86dde898>,\n",
              " 'activation_19': <keras.layers.core.Activation at 0x22e86e4cd30>,\n",
              " 'mixed1': <keras.layers.merge.Concatenate at 0x22e86ef5f98>,\n",
              " 'conv2d_23': <keras.layers.convolutional.Conv2D at 0x22e87218be0>,\n",
              " 'batch_normalization_23': <keras.layers.normalization.BatchNormalization at 0x22e87251da0>,\n",
              " 'activation_23': <keras.layers.core.Activation at 0x22e87218e80>,\n",
              " 'conv2d_21': <keras.layers.convolutional.Conv2D at 0x22e86b14d30>,\n",
              " 'conv2d_24': <keras.layers.convolutional.Conv2D at 0x22e8734e4a8>,\n",
              " 'batch_normalization_21': <keras.layers.normalization.BatchNormalization at 0x22e870d3ba8>,\n",
              " 'batch_normalization_24': <keras.layers.normalization.BatchNormalization at 0x22e87390fd0>,\n",
              " 'activation_21': <keras.layers.core.Activation at 0x22e8706c668>,\n",
              " 'activation_24': <keras.layers.core.Activation at 0x22e87378940>,\n",
              " 'average_pooling2d_3': <keras.layers.pooling.AveragePooling2D at 0x22e8746d390>,\n",
              " 'conv2d_20': <keras.layers.convolutional.Conv2D at 0x22e86ef5c88>,\n",
              " 'conv2d_22': <keras.layers.convolutional.Conv2D at 0x22e87050780>,\n",
              " 'conv2d_25': <keras.layers.convolutional.Conv2D at 0x22e87455518>,\n",
              " 'conv2d_26': <keras.layers.convolutional.Conv2D at 0x22e8754b780>,\n",
              " 'batch_normalization_20': <keras.layers.normalization.BatchNormalization at 0x22e86ff4e10>,\n",
              " 'batch_normalization_22': <keras.layers.normalization.BatchNormalization at 0x22e8714acc0>,\n",
              " 'batch_normalization_25': <keras.layers.normalization.BatchNormalization at 0x22e8748fd68>,\n",
              " 'batch_normalization_26': <keras.layers.normalization.BatchNormalization at 0x22e875b8518>,\n",
              " 'activation_20': <keras.layers.core.Activation at 0x22e86c33b70>,\n",
              " 'activation_22': <keras.layers.core.Activation at 0x22e87174ac8>,\n",
              " 'activation_25': <keras.layers.core.Activation at 0x22e87522e80>,\n",
              " 'activation_26': <keras.layers.core.Activation at 0x22e87594b70>,\n",
              " 'mixed2': <keras.layers.merge.Concatenate at 0x22e87639da0>,\n",
              " 'conv2d_28': <keras.layers.convolutional.Conv2D at 0x22e87771438>,\n",
              " 'batch_normalization_28': <keras.layers.normalization.BatchNormalization at 0x22e877b1c88>,\n",
              " 'activation_28': <keras.layers.core.Activation at 0x22e88812390>,\n",
              " 'conv2d_29': <keras.layers.convolutional.Conv2D at 0x22e888e9be0>,\n",
              " 'batch_normalization_29': <keras.layers.normalization.BatchNormalization at 0x22e888606d8>,\n",
              " 'activation_29': <keras.layers.core.Activation at 0x22e8886f550>,\n",
              " 'conv2d_27': <keras.layers.convolutional.Conv2D at 0x22e87639978>,\n",
              " 'conv2d_30': <keras.layers.convolutional.Conv2D at 0x22e8892bd68>,\n",
              " 'batch_normalization_27': <keras.layers.normalization.BatchNormalization at 0x22e87675dd8>,\n",
              " 'batch_normalization_30': <keras.layers.normalization.BatchNormalization at 0x22e88966e10>,\n",
              " 'activation_27': <keras.layers.core.Activation at 0x22e87693438>,\n",
              " 'activation_30': <keras.layers.core.Activation at 0x22e889874a8>,\n",
              " 'max_pooling2d_3': <keras.layers.pooling.MaxPooling2D at 0x22e88a673c8>,\n",
              " 'mixed3': <keras.layers.merge.Concatenate at 0x22e88a32fd0>,\n",
              " 'conv2d_35': <keras.layers.convolutional.Conv2D at 0x22e88e553c8>,\n",
              " 'batch_normalization_35': <keras.layers.normalization.BatchNormalization at 0x22e88ecada0>,\n",
              " 'activation_35': <keras.layers.core.Activation at 0x22e88f59da0>,\n",
              " 'conv2d_36': <keras.layers.convolutional.Conv2D at 0x22e88eadcf8>,\n",
              " 'batch_normalization_36': <keras.layers.normalization.BatchNormalization at 0x22e88fcc438>,\n",
              " 'activation_36': <keras.layers.core.Activation at 0x22e88fa5cf8>,\n",
              " 'conv2d_32': <keras.layers.convolutional.Conv2D at 0x22e88b6bb00>,\n",
              " 'conv2d_37': <keras.layers.convolutional.Conv2D at 0x22e89084e80>,\n",
              " 'batch_normalization_32': <keras.layers.normalization.BatchNormalization at 0x22e88b839b0>,\n",
              " 'batch_normalization_37': <keras.layers.normalization.BatchNormalization at 0x22e890ab9e8>,\n",
              " 'activation_32': <keras.layers.core.Activation at 0x22e88b83be0>,\n",
              " 'activation_37': <keras.layers.core.Activation at 0x22e890cccf8>,\n",
              " 'conv2d_33': <keras.layers.convolutional.Conv2D at 0x22e88ba8f98>,\n",
              " 'conv2d_38': <keras.layers.convolutional.Conv2D at 0x22e89179b00>,\n",
              " 'batch_normalization_33': <keras.layers.normalization.BatchNormalization at 0x22e88c89a20>,\n",
              " 'batch_normalization_38': <keras.layers.normalization.BatchNormalization at 0x22e891ac0f0>,\n",
              " 'activation_33': <keras.layers.core.Activation at 0x22e88ca7d30>,\n",
              " 'activation_38': <keras.layers.core.Activation at 0x22e891d5dd8>,\n",
              " 'average_pooling2d_4': <keras.layers.pooling.AveragePooling2D at 0x22e892d0c50>,\n",
              " 'conv2d_31': <keras.layers.convolutional.Conv2D at 0x22e88a32eb8>,\n",
              " 'conv2d_34': <keras.layers.convolutional.Conv2D at 0x22e88d56b38>,\n",
              " 'conv2d_39': <keras.layers.convolutional.Conv2D at 0x22e89277588>,\n",
              " 'conv2d_40': <keras.layers.convolutional.Conv2D at 0x22e893a9668>,\n",
              " 'batch_normalization_31': <keras.layers.normalization.BatchNormalization at 0x22e88a8e6a0>,\n",
              " 'batch_normalization_34': <keras.layers.normalization.BatchNormalization at 0x22e88d8a550>,\n",
              " 'batch_normalization_39': <keras.layers.normalization.BatchNormalization at 0x22e892ebc50>,\n",
              " 'batch_normalization_40': <keras.layers.normalization.BatchNormalization at 0x22e893cbeb8>,\n",
              " 'activation_31': <keras.layers.core.Activation at 0x22e88b34cf8>,\n",
              " 'activation_34': <keras.layers.core.Activation at 0x22e88df3eb8>,\n",
              " 'activation_39': <keras.layers.core.Activation at 0x22e89380d68>,\n",
              " 'activation_40': <keras.layers.core.Activation at 0x22e893cbc50>,\n",
              " 'mixed4': <keras.layers.merge.Concatenate at 0x22e89499a58>,\n",
              " 'conv2d_45': <keras.layers.convolutional.Conv2D at 0x22e898c4b00>,\n",
              " 'batch_normalization_45': <keras.layers.normalization.BatchNormalization at 0x22e898f50f0>,\n",
              " 'activation_45': <keras.layers.core.Activation at 0x22e898c4c18>,\n",
              " 'conv2d_46': <keras.layers.convolutional.Conv2D at 0x22e8991de80>,\n",
              " 'batch_normalization_46': <keras.layers.normalization.BatchNormalization at 0x22e89a418d0>,\n",
              " 'activation_46': <keras.layers.core.Activation at 0x22e89acce10>,\n",
              " 'conv2d_42': <keras.layers.convolutional.Conv2D at 0x22e8959def0>,\n",
              " 'conv2d_47': <keras.layers.convolutional.Conv2D at 0x22e89a252e8>,\n",
              " 'batch_normalization_42': <keras.layers.normalization.BatchNormalization at 0x22e896118d0>,\n",
              " 'batch_normalization_47': <keras.layers.normalization.BatchNormalization at 0x22e89b07d68>,\n",
              " 'activation_42': <keras.layers.core.Activation at 0x22e896a5e80>,\n",
              " 'activation_47': <keras.layers.core.Activation at 0x22e89b19860>,\n",
              " 'conv2d_43': <keras.layers.convolutional.Conv2D at 0x22e895f4780>,\n",
              " 'conv2d_48': <keras.layers.convolutional.Conv2D at 0x22e89bf6e48>,\n",
              " 'batch_normalization_43': <keras.layers.normalization.BatchNormalization at 0x22e89715438>,\n",
              " 'batch_normalization_48': <keras.layers.normalization.BatchNormalization at 0x22e89c1fdd8>,\n",
              " 'activation_43': <keras.layers.core.Activation at 0x22e896f2cf8>,\n",
              " 'activation_48': <keras.layers.core.Activation at 0x22e89c40908>,\n",
              " 'average_pooling2d_5': <keras.layers.pooling.AveragePooling2D at 0x22e89deb550>,\n",
              " 'conv2d_41': <keras.layers.convolutional.Conv2D at 0x22e894995c0>,\n",
              " 'conv2d_44': <keras.layers.convolutional.Conv2D at 0x22e897d1e80>,\n",
              " 'conv2d_49': <keras.layers.convolutional.Conv2D at 0x22e89ceed68>,\n",
              " 'conv2d_50': <keras.layers.convolutional.Conv2D at 0x22e89deb978>,\n",
              " 'batch_normalization_41': <keras.layers.normalization.BatchNormalization at 0x22e894f3ac8>,\n",
              " 'batch_normalization_44': <keras.layers.normalization.BatchNormalization at 0x22e897f49e8>,\n",
              " 'batch_normalization_49': <keras.layers.normalization.BatchNormalization at 0x22e89d1eeb8>,\n",
              " 'batch_normalization_50': <keras.layers.normalization.BatchNormalization at 0x22e89ef2da0>,\n",
              " 'activation_41': <keras.layers.core.Activation at 0x22e894f3668>,\n",
              " 'activation_44': <keras.layers.core.Activation at 0x22e89814cf8>,\n",
              " 'activation_49': <keras.layers.core.Activation at 0x22e89d46da0>,\n",
              " 'activation_50': <keras.layers.core.Activation at 0x22e89e47710>,\n",
              " 'mixed5': <keras.layers.merge.Concatenate at 0x22e89f1bd30>,\n",
              " 'conv2d_55': <keras.layers.convolutional.Conv2D at 0x22e8a343e80>,\n",
              " 'batch_normalization_55': <keras.layers.normalization.BatchNormalization at 0x22e8a3689e8>,\n",
              " 'activation_55': <keras.layers.core.Activation at 0x22e8a41d7f0>,\n",
              " 'conv2d_56': <keras.layers.convolutional.Conv2D at 0x22e8a436f28>,\n",
              " 'batch_normalization_56': <keras.layers.normalization.BatchNormalization at 0x22e8a46ae10>,\n",
              " 'activation_56': <keras.layers.core.Activation at 0x22e8a4919b0>,\n",
              " 'conv2d_52': <keras.layers.convolutional.Conv2D at 0x22e8a00c9e8>,\n",
              " 'conv2d_57': <keras.layers.convolutional.Conv2D at 0x22e8a53af98>,\n",
              " 'batch_normalization_52': <keras.layers.normalization.BatchNormalization at 0x22e8a0462b0>,\n",
              " 'batch_normalization_57': <keras.layers.normalization.BatchNormalization at 0x22e8a5b58d0>,\n",
              " 'activation_52': <keras.layers.core.Activation at 0x22e8a00c438>,\n",
              " 'activation_57': <keras.layers.core.Activation at 0x22e8a63ee10>,\n",
              " 'conv2d_53': <keras.layers.convolutional.Conv2D at 0x22e8a06a7b8>,\n",
              " 'conv2d_58': <keras.layers.convolutional.Conv2D at 0x22e8a5962e8>,\n",
              " 'batch_normalization_53': <keras.layers.normalization.BatchNormalization at 0x22e8a186da0>,\n",
              " 'batch_normalization_58': <keras.layers.normalization.BatchNormalization at 0x22e8a6afd68>,\n",
              " 'activation_53': <keras.layers.core.Activation at 0x22e8a216e48>,\n",
              " 'activation_58': <keras.layers.core.Activation at 0x22e8a68d860>,\n",
              " 'average_pooling2d_6': <keras.layers.pooling.AveragePooling2D at 0x22e8a85eeb8>,\n",
              " 'conv2d_51': <keras.layers.convolutional.Conv2D at 0x22e89f1b8d0>,\n",
              " 'conv2d_54': <keras.layers.convolutional.Conv2D at 0x22e8a171320>,\n",
              " 'conv2d_59': <keras.layers.convolutional.Conv2D at 0x22e8a769e48>,\n",
              " 'conv2d_60': <keras.layers.convolutional.Conv2D at 0x22e8a85e8d0>,\n",
              " 'batch_normalization_51': <keras.layers.normalization.BatchNormalization at 0x22e89ff7c88>,\n",
              " 'batch_normalization_54': <keras.layers.normalization.BatchNormalization at 0x22e8a288438>,\n",
              " 'batch_normalization_59': <keras.layers.normalization.BatchNormalization at 0x22e8a791dd8>,\n",
              " 'batch_normalization_60': <keras.layers.normalization.BatchNormalization at 0x22e8a8b83c8>,\n",
              " 'activation_51': <keras.layers.core.Activation at 0x22e89f65a58>,\n",
              " 'activation_54': <keras.layers.core.Activation at 0x22e8a261cf8>,\n",
              " 'activation_59': <keras.layers.core.Activation at 0x22e8a7af908>,\n",
              " 'activation_60': <keras.layers.core.Activation at 0x22e8a8b8da0>,\n",
              " 'mixed6': <keras.layers.merge.Concatenate at 0x22e8a987320>,\n",
              " 'conv2d_65': <keras.layers.convolutional.Conv2D at 0x22e8ad9c6a0>,\n",
              " 'batch_normalization_65': <keras.layers.normalization.BatchNormalization at 0x22e8ade45c0>,\n",
              " 'activation_65': <keras.layers.core.Activation at 0x22e8ade4c88>,\n",
              " 'conv2d_66': <keras.layers.convolutional.Conv2D at 0x22e8adc2e80>,\n",
              " 'batch_normalization_66': <keras.layers.normalization.BatchNormalization at 0x22e8be97cf8>,\n",
              " 'activation_66': <keras.layers.core.Activation at 0x22e8bea5f60>,\n",
              " 'conv2d_62': <keras.layers.convolutional.Conv2D at 0x22e8aa7bd68>,\n",
              " 'conv2d_67': <keras.layers.convolutional.Conv2D at 0x22e8bf64fd0>,\n",
              " 'batch_normalization_62': <keras.layers.normalization.BatchNormalization at 0x22e8aa9bb00>,\n",
              " 'batch_normalization_67': <keras.layers.normalization.BatchNormalization at 0x22e8bfa0e10>,\n",
              " 'activation_62': <keras.layers.core.Activation at 0x22e8ab527b8>,\n",
              " 'activation_67': <keras.layers.core.Activation at 0x22e8bfbcb70>,\n",
              " 'conv2d_63': <keras.layers.convolutional.Conv2D at 0x22e8aabfb00>,\n",
              " 'conv2d_68': <keras.layers.convolutional.Conv2D at 0x22e8c065fd0>,\n",
              " 'batch_normalization_63': <keras.layers.normalization.BatchNormalization at 0x22e8ab9fef0>,\n",
              " 'batch_normalization_68': <keras.layers.normalization.BatchNormalization at 0x22e8c0dec88>,\n",
              " 'activation_63': <keras.layers.core.Activation at 0x22e8abc3f98>,\n",
              " 'activation_68': <keras.layers.core.Activation at 0x22e8c0c6d30>,\n",
              " 'average_pooling2d_7': <keras.layers.pooling.AveragePooling2D at 0x22e8c1bcc18>,\n",
              " 'conv2d_61': <keras.layers.convolutional.Conv2D at 0x22e8a954a20>,\n",
              " 'conv2d_64': <keras.layers.convolutional.Conv2D at 0x22e8ac70f28>,\n",
              " 'conv2d_69': <keras.layers.convolutional.Conv2D at 0x22e8c193668>,\n",
              " 'conv2d_70': <keras.layers.convolutional.Conv2D at 0x22e8c293400>,\n",
              " 'batch_normalization_61': <keras.layers.normalization.BatchNormalization at 0x22e8aa52eb8>,\n",
              " 'batch_normalization_64': <keras.layers.normalization.BatchNormalization at 0x22e8ace5cc0>,\n",
              " 'batch_normalization_69': <keras.layers.normalization.BatchNormalization at 0x22e8c1db780>,\n",
              " 'batch_normalization_70': <keras.layers.normalization.BatchNormalization at 0x22e8c36eac8>,\n",
              " 'activation_61': <keras.layers.core.Activation at 0x22e8a9a6d30>,\n",
              " 'activation_64': <keras.layers.core.Activation at 0x22e8acceac8>,\n",
              " 'activation_69': <keras.layers.core.Activation at 0x22e8c26e160>,\n",
              " 'activation_70': <keras.layers.core.Activation at 0x22e8c2dcd68>,\n",
              " 'mixed7': <keras.layers.merge.Concatenate at 0x22e8c387cf8>,\n",
              " 'conv2d_73': <keras.layers.convolutional.Conv2D at 0x22e8c4e5240>,\n",
              " 'batch_normalization_73': <keras.layers.normalization.BatchNormalization at 0x22e8c5dee10>,\n",
              " 'activation_73': <keras.layers.core.Activation at 0x22e8c628940>,\n",
              " 'conv2d_74': <keras.layers.convolutional.Conv2D at 0x22e8c6ae390>,\n",
              " 'batch_normalization_74': <keras.layers.normalization.BatchNormalization at 0x22e8c6de828>,\n",
              " 'activation_74': <keras.layers.core.Activation at 0x22e8c6fe668>,\n",
              " 'conv2d_71': <keras.layers.convolutional.Conv2D at 0x22e8c387470>,\n",
              " 'conv2d_75': <keras.layers.convolutional.Conv2D at 0x22e8c7a3e48>,\n",
              " 'batch_normalization_71': <keras.layers.normalization.BatchNormalization at 0x22e8c3fe9b0>,\n",
              " 'batch_normalization_75': <keras.layers.normalization.BatchNormalization at 0x22e8c818c50>,\n",
              " 'activation_71': <keras.layers.core.Activation at 0x22e8c45d7b8>,\n",
              " 'activation_75': <keras.layers.core.Activation at 0x22e8c7fdf98>,\n",
              " 'conv2d_72': <keras.layers.convolutional.Conv2D at 0x22e8c3e4208>,\n",
              " 'conv2d_76': <keras.layers.convolutional.Conv2D at 0x22e8c8a3c18>,\n",
              " 'batch_normalization_72': <keras.layers.normalization.BatchNormalization at 0x22e8c500b38>,\n",
              " 'batch_normalization_76': <keras.layers.normalization.BatchNormalization at 0x22e8c918780>,\n",
              " 'activation_72': <keras.layers.core.Activation at 0x22e8c569e48>,\n",
              " 'activation_76': <keras.layers.core.Activation at 0x22e8c9ad160>,\n",
              " 'max_pooling2d_4': <keras.layers.pooling.MaxPooling2D at 0x22e8c8f6c18>,\n",
              " 'mixed8': <keras.layers.merge.Concatenate at 0x22e8c9cf400>,\n",
              " 'conv2d_81': <keras.layers.convolutional.Conv2D at 0x22e8cd43c88>,\n",
              " 'batch_normalization_81': <keras.layers.normalization.BatchNormalization at 0x22e8ced64e0>,\n",
              " 'activation_81': <keras.layers.core.Activation at 0x22e8cef1630>,\n",
              " 'conv2d_78': <keras.layers.convolutional.Conv2D at 0x22e8caf66d8>,\n",
              " 'conv2d_82': <keras.layers.convolutional.Conv2D at 0x22e8cf234e0>,\n",
              " 'batch_normalization_78': <keras.layers.normalization.BatchNormalization at 0x22e8cb3dcc0>,\n",
              " 'batch_normalization_82': <keras.layers.normalization.BatchNormalization at 0x22e8cf68b38>,\n",
              " 'activation_78': <keras.layers.core.Activation at 0x22e8cac4fd0>,\n",
              " 'activation_82': <keras.layers.core.Activation at 0x22e8cf4e978>,\n",
              " 'conv2d_79': <keras.layers.convolutional.Conv2D at 0x22e8cb24ac8>,\n",
              " 'conv2d_80': <keras.layers.convolutional.Conv2D at 0x22e8cc1ad68>,\n",
              " 'conv2d_83': <keras.layers.convolutional.Conv2D at 0x22e8d01d5f8>,\n",
              " 'conv2d_84': <keras.layers.convolutional.Conv2D at 0x22e8d047f60>,\n",
              " 'average_pooling2d_8': <keras.layers.pooling.AveragePooling2D at 0x22e8d16fcf8>,\n",
              " 'conv2d_77': <keras.layers.convolutional.Conv2D at 0x22e8ca6b400>,\n",
              " 'batch_normalization_79': <keras.layers.normalization.BatchNormalization at 0x22e8cc40eb8>,\n",
              " 'batch_normalization_80': <keras.layers.normalization.BatchNormalization at 0x22e8cd19cf8>,\n",
              " 'batch_normalization_83': <keras.layers.normalization.BatchNormalization at 0x22e8d068710>,\n",
              " 'batch_normalization_84': <keras.layers.normalization.BatchNormalization at 0x22e8d146d68>,\n",
              " 'conv2d_85': <keras.layers.convolutional.Conv2D at 0x22e8d308550>,\n",
              " 'batch_normalization_77': <keras.layers.normalization.BatchNormalization at 0x22e8ca1b6d8>,\n",
              " 'activation_79': <keras.layers.core.Activation at 0x22e8ccd10f0>,\n",
              " 'activation_80': <keras.layers.core.Activation at 0x22e8cdd2d68>,\n",
              " 'activation_83': <keras.layers.core.Activation at 0x22e8d0fd160>,\n",
              " 'activation_84': <keras.layers.core.Activation at 0x22e8d2006a0>,\n",
              " 'batch_normalization_85': <keras.layers.normalization.BatchNormalization at 0x22e8d270c18>,\n",
              " 'activation_77': <keras.layers.core.Activation at 0x22e8ca1bc18>,\n",
              " 'mixed9_0': <keras.layers.merge.Concatenate at 0x22e8cd43b00>,\n",
              " 'concatenate_1': <keras.layers.merge.Concatenate at 0x22e8d16f9b0>,\n",
              " 'activation_85': <keras.layers.core.Activation at 0x22e8d2703c8>,\n",
              " 'mixed9': <keras.layers.merge.Concatenate at 0x22e8d31d160>,\n",
              " 'conv2d_90': <keras.layers.convolutional.Conv2D at 0x22e8d69f470>,\n",
              " 'batch_normalization_90': <keras.layers.normalization.BatchNormalization at 0x22e8d84e5f8>,\n",
              " 'activation_90': <keras.layers.core.Activation at 0x22e8d84eeb8>,\n",
              " 'conv2d_87': <keras.layers.convolutional.Conv2D at 0x22e8d44dda0>,\n",
              " 'conv2d_91': <keras.layers.convolutional.Conv2D at 0x22e8d870f60>,\n",
              " 'batch_normalization_87': <keras.layers.normalization.BatchNormalization at 0x22e8d46bdd8>,\n",
              " 'batch_normalization_91': <keras.layers.normalization.BatchNormalization at 0x22e8d896dd8>,\n",
              " 'activation_87': <keras.layers.core.Activation at 0x22e8d526128>,\n",
              " 'activation_91': <keras.layers.core.Activation at 0x22e8d8be0f0>,\n",
              " 'conv2d_88': <keras.layers.convolutional.Conv2D at 0x22e8d48eb38>,\n",
              " 'conv2d_89': <keras.layers.convolutional.Conv2D at 0x22e8d642f60>,\n",
              " 'conv2d_92': <keras.layers.convolutional.Conv2D at 0x22e8d96acc0>,\n",
              " 'conv2d_93': <keras.layers.convolutional.Conv2D at 0x22e8da6dc50>,\n",
              " 'average_pooling2d_9': <keras.layers.pooling.AveragePooling2D at 0x22e8daca320>,\n",
              " 'conv2d_86': <keras.layers.convolutional.Conv2D at 0x22e8d3525c0>,\n",
              " 'batch_normalization_88': <keras.layers.normalization.BatchNormalization at 0x22e8d570e10>,\n",
              " 'batch_normalization_89': <keras.layers.normalization.BatchNormalization at 0x22e8d6bacc0>,\n",
              " 'batch_normalization_92': <keras.layers.normalization.BatchNormalization at 0x22e8d99c320>,\n",
              " 'batch_normalization_93': <keras.layers.normalization.BatchNormalization at 0x22e8dadfda0>,\n",
              " 'conv2d_94': <keras.layers.convolutional.Conv2D at 0x22e8dbe4e80>,\n",
              " 'batch_normalization_86': <keras.layers.normalization.BatchNormalization at 0x22e8d423ef0>,\n",
              " 'activation_88': <keras.layers.core.Activation at 0x22e8d597588>,\n",
              " 'activation_89': <keras.layers.core.Activation at 0x22e8d6429b0>,\n",
              " 'activation_92': <keras.layers.core.Activation at 0x22e8d9bf9e8>,\n",
              " 'activation_93': <keras.layers.core.Activation at 0x22e8db71e48>,\n",
              " 'batch_normalization_94': <keras.layers.normalization.BatchNormalization at 0x22e8dbc09b0>,\n",
              " 'activation_86': <keras.layers.core.Activation at 0x22e8d3762b0>,\n",
              " 'mixed9_1': <keras.layers.merge.Concatenate at 0x22e8d69fb38>,\n",
              " 'concatenate_2': <keras.layers.merge.Concatenate at 0x22e8daca6a0>,\n",
              " 'activation_94': <keras.layers.core.Activation at 0x22e8dbc0860>,\n",
              " 'mixed10': <keras.layers.merge.Concatenate at 0x22e8dc9c780>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2syM-DPHXBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss will be changed so, we declare it as a variable\n",
        "loss = K.variable(0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCmsRlfUHXBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer_name in layer_contributions:\n",
        "    # coefficients quantifies how much eac layer's activations contibutes to the loss that we want to maximize\n",
        "    coefficient = layer_contributions[layer_name]\n",
        "    # the output of a layer\n",
        "    activation = layer_dict[layer_name].output\n",
        "    scaling_factor = K.prod(K.cast(K.shape(activation), 'float32'))\n",
        "    # loss is sum of losses in all layers\n",
        "    loss = loss + coefficient*K.sum(K.square(activation))/scaling_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOwuaPLuHXBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The tensor dream holds the generated image\n",
        "deep_dream = model.input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0BiIcXtHXBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we calculate the gradient of the input image wrt our loss function\n",
        "gradients = K.gradients(loss, deep_dream)[0]\n",
        "# gradient normalizaation - turns out that this is important step\n",
        "gradients /= K.maximum(K.mean(K.abs(gradients)), 0.0000001)\n",
        "outputs = [loss, gradients]\n",
        "\n",
        "loss_and_grads = K.function([deep_dream], [loss, gradients])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EUIdoUJHXBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_ascent(x, iterations, step, max_loss = None):\n",
        "    loss_value, grads_value = 0,0\n",
        "    for i in range(iterations):\n",
        "        loss_value, grads_value = loss_and_grads([x])\n",
        "        # if our loss function gets to the max value then we should break\n",
        "        # deep dreams won't look pretty if we procede in the following steps\n",
        "        if max_loss is not None and loss_value > max_loss:\n",
        "            break\n",
        "        print('Loss value at iteration ', i, ':', loss_value)\n",
        "    \n",
        "        # we update the input image\n",
        "        # this is the crucial step for making the deep dreams\n",
        "        x += step*grads_value\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhOjnTCkHXBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(image_path):\n",
        "    # load the image in the PIL format\n",
        "    img = load_img(image_path)\n",
        "    # make a NumPy array of it\n",
        "    img = img_to_array(img)\n",
        "    # make a 4D tennsor of it\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "    # preprocessing steps for feeding the image through the inception_v3 \n",
        "    img = inception_v3.preprocess_input(img)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQrFc4nOHXBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deprocess(x):\n",
        "    # making an image out of tensor\n",
        "    x = x.reshape(x.shape[1], x.shape[2], 3) \n",
        "    x/=2\n",
        "    x+=0.5\n",
        "    x*=255.\n",
        "    image = np.clip(x, 0,255).astype('uint8')\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dH2XGMGHXBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_img(x, size):\n",
        "    img = x.copy()\n",
        "    factors = (1, float(size[0]/img.shape[1]),float(size[1]/img.shape[2]), 1)\n",
        "    return zoom(img, factors, order = 1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL9-aLOzHXBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_img(img, fname):\n",
        "    pil_img = deprocess(np.copy(img))\n",
        "    imwrite(fname, pil_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M_nfCKDHXBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = {\"image_path\" : 'got.jpg',\n",
        "       \"l_rate\" : 0.01,\n",
        "       \"num_octave\" : 3,\n",
        "       \"octave_scale\" : 1.4,\n",
        "       \"iterations\" : 30,\n",
        "       \"max_loss\" : 50.,\n",
        "    \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCXPGUQCHXBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deep_dream(image_path, l_rate, num_octave, octave_scale, iterations, max_loss):\n",
        "    \n",
        "    img_preprocessed = preprocess(image_path)\n",
        "    # processed image has the batch dimension\n",
        "    original_shape = img_preprocessed.shape[1:3]\n",
        "    successive_shapes = [original_shape]\n",
        "    \n",
        "    original_img = img_preprocessed.copy()\n",
        "    shrunck_original_img = resize_img(original_img, successive_shapes[0]) # we take the smallest shape\n",
        "    \n",
        "    for i in range(0, num_octave):\n",
        "        shape = tuple([int(dim/(octave_scale**i)) for dim in original_shape] )\n",
        "        successive_shapes.append(shape)\n",
        "    successive_shapes = successive_shapes[::-1]\n",
        "    print('Shapes of original image, that we will procss: ', successive_shapes)\n",
        "    \n",
        "    for shape in successive_shapes:\n",
        "        print('Preprocessing image shape: ', shape)\n",
        "        img = resize_img(img_preprocessed, shape)\n",
        "        # appying gradient ascent for each scale\n",
        "        img = gradient_ascent(img, iterations = iterations, step = l_rate, max_loss = max_loss)\n",
        "        upscaled_shrunk_original_img = resize_img(shrunck_original_img, shape)\n",
        "        same_size_original = resize_img(original_img, shape)\n",
        "        # calculating the lost detail\n",
        "        lost_detail = same_size_original - upscaled_shrunk_original_img\n",
        "        img += lost_detail\n",
        "        # preparing for the next iteration \n",
        "        shrunk_original_img = resize_img(original_img, shape)\n",
        "        name = ''.join(list(image_path)[:-4])+'_dream_at_shape'+str(shape)+'.jpg'\n",
        "        save_img(img, fname = name)\n",
        "    \n",
        "    #saving final image\n",
        "    f_name = ''.join(list(image_path)[:-4])+'_final_dream.jpg'\n",
        "    save_img(img, fname = f_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQRRbPxJHXBq",
        "colab_type": "code",
        "colab": {},
        "outputId": "a54405cf-20e3-4ef9-a413-a35ce8272224"
      },
      "source": [
        "deep_dream(**cfg)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes of original image, that we will procss:  [(704, 1056), (985, 1478), (1380, 2070), (1380, 2070)]\n",
            "Preprocessing image shape:  (704, 1056)\n",
            "Loss value at iteration  0 : 2.5999277\n",
            "Loss value at iteration  1 : 3.162093\n",
            "Loss value at iteration  2 : 3.9012845\n",
            "Loss value at iteration  3 : 4.699877\n",
            "Loss value at iteration  4 : 5.579523\n",
            "Loss value at iteration  5 : 6.49706\n",
            "Loss value at iteration  6 : 7.4140587\n",
            "Loss value at iteration  7 : 8.304545\n",
            "Loss value at iteration  8 : 9.163407\n",
            "Loss value at iteration  9 : 10.009405\n",
            "Loss value at iteration  10 : 10.804069\n",
            "Loss value at iteration  11 : 11.58229\n",
            "Loss value at iteration  12 : 12.326757\n",
            "Loss value at iteration  13 : 13.031355\n",
            "Loss value at iteration  14 : 13.724984\n",
            "Loss value at iteration  15 : 14.383502\n",
            "Loss value at iteration  16 : 15.015279\n",
            "Loss value at iteration  17 : 15.65203\n",
            "Loss value at iteration  18 : 16.236258\n",
            "Loss value at iteration  19 : 16.825583\n",
            "Loss value at iteration  20 : 17.388685\n",
            "Loss value at iteration  21 : 17.951757\n",
            "Loss value at iteration  22 : 18.480581\n",
            "Loss value at iteration  23 : 19.0166\n",
            "Loss value at iteration  24 : 19.535387\n",
            "Loss value at iteration  25 : 20.04503\n",
            "Loss value at iteration  26 : 20.518074\n",
            "Loss value at iteration  27 : 21.018047\n",
            "Loss value at iteration  28 : 21.473751\n",
            "Loss value at iteration  29 : 21.953053\n",
            "Preprocessing image shape:  (985, 1478)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Andjelka\\Anaconda3\\envs\\tensorflow sessions\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
            "  \"the returned array has changed.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss value at iteration  0 : 2.313983\n",
            "Loss value at iteration  1 : 2.7449858\n",
            "Loss value at iteration  2 : 3.3896003\n",
            "Loss value at iteration  3 : 4.143696\n",
            "Loss value at iteration  4 : 4.9998417\n",
            "Loss value at iteration  5 : 5.944893\n",
            "Loss value at iteration  6 : 6.916074\n",
            "Loss value at iteration  7 : 7.878686\n",
            "Loss value at iteration  8 : 8.824211\n",
            "Loss value at iteration  9 : 9.722062\n",
            "Loss value at iteration  10 : 10.616051\n",
            "Loss value at iteration  11 : 11.460037\n",
            "Loss value at iteration  12 : 12.273386\n",
            "Loss value at iteration  13 : 13.074901\n",
            "Loss value at iteration  14 : 13.822903\n",
            "Loss value at iteration  15 : 14.564393\n",
            "Loss value at iteration  16 : 15.27522\n",
            "Loss value at iteration  17 : 15.972214\n",
            "Loss value at iteration  18 : 16.658207\n",
            "Loss value at iteration  19 : 17.314932\n",
            "Loss value at iteration  20 : 17.953707\n",
            "Loss value at iteration  21 : 18.584803\n",
            "Loss value at iteration  22 : 19.18418\n",
            "Loss value at iteration  23 : 19.775816\n",
            "Loss value at iteration  24 : 20.362616\n",
            "Loss value at iteration  25 : 20.927034\n",
            "Loss value at iteration  26 : 21.476671\n",
            "Loss value at iteration  27 : 22.024845\n",
            "Loss value at iteration  28 : 22.548489\n",
            "Loss value at iteration  29 : 23.069859\n",
            "Preprocessing image shape:  (1380, 2070)\n",
            "Loss value at iteration  0 : 2.1114635\n",
            "Loss value at iteration  1 : 2.4126887\n",
            "Loss value at iteration  2 : 3.016458\n",
            "Loss value at iteration  3 : 3.7937856\n",
            "Loss value at iteration  4 : 4.702565\n",
            "Loss value at iteration  5 : 5.6886353\n",
            "Loss value at iteration  6 : 6.7054114\n",
            "Loss value at iteration  7 : 7.7214274\n",
            "Loss value at iteration  8 : 8.719277\n",
            "Loss value at iteration  9 : 9.693655\n",
            "Loss value at iteration  10 : 10.630697\n",
            "Loss value at iteration  11 : 11.547394\n",
            "Loss value at iteration  12 : 12.424993\n",
            "Loss value at iteration  13 : 13.277938\n",
            "Loss value at iteration  14 : 14.101023\n",
            "Loss value at iteration  15 : 14.913628\n",
            "Loss value at iteration  16 : 15.692983\n",
            "Loss value at iteration  17 : 16.447096\n",
            "Loss value at iteration  18 : 17.179007\n",
            "Loss value at iteration  19 : 17.888361\n",
            "Loss value at iteration  20 : 18.580408\n",
            "Loss value at iteration  21 : 19.246048\n",
            "Loss value at iteration  22 : 19.909376\n",
            "Loss value at iteration  23 : 20.535412\n",
            "Loss value at iteration  24 : 21.159632\n",
            "Loss value at iteration  25 : 21.75301\n",
            "Loss value at iteration  26 : 22.33241\n",
            "Loss value at iteration  27 : 22.907864\n",
            "Loss value at iteration  28 : 23.466288\n",
            "Loss value at iteration  29 : 24.014273\n",
            "Preprocessing image shape:  (1380, 2070)\n",
            "Loss value at iteration  0 : 2.1114635\n",
            "Loss value at iteration  1 : 2.4126887\n",
            "Loss value at iteration  2 : 3.016458\n",
            "Loss value at iteration  3 : 3.7937856\n",
            "Loss value at iteration  4 : 4.702565\n",
            "Loss value at iteration  5 : 5.6886353\n",
            "Loss value at iteration  6 : 6.7054114\n",
            "Loss value at iteration  7 : 7.7214274\n",
            "Loss value at iteration  8 : 8.719277\n",
            "Loss value at iteration  9 : 9.693655\n",
            "Loss value at iteration  10 : 10.630697\n",
            "Loss value at iteration  11 : 11.547394\n",
            "Loss value at iteration  12 : 12.424993\n",
            "Loss value at iteration  13 : 13.277938\n",
            "Loss value at iteration  14 : 14.101023\n",
            "Loss value at iteration  15 : 14.913628\n",
            "Loss value at iteration  16 : 15.692983\n",
            "Loss value at iteration  17 : 16.447096\n",
            "Loss value at iteration  18 : 17.179007\n",
            "Loss value at iteration  19 : 17.888361\n",
            "Loss value at iteration  20 : 18.580408\n",
            "Loss value at iteration  21 : 19.246048\n",
            "Loss value at iteration  22 : 19.909376\n",
            "Loss value at iteration  23 : 20.535412\n",
            "Loss value at iteration  24 : 21.159632\n",
            "Loss value at iteration  25 : 21.75301\n",
            "Loss value at iteration  26 : 22.33241\n",
            "Loss value at iteration  27 : 22.907864\n",
            "Loss value at iteration  28 : 23.466288\n",
            "Loss value at iteration  29 : 24.014273\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}